{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import all of the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch import tensor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dropping Data that do not have weight / contribute to their survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass Sex   Age  SibSp  Parch\n",
      "0         3   0  22.0      1      0\n",
      "1         1   1  38.0      1      0\n",
      "2         3   1  26.0      0      0\n",
      "3         1   1  35.0      1      0\n",
      "4         3   0  35.0      0      0\n",
      "..      ...  ..   ...    ...    ...\n",
      "885       3   1  39.0      0      5\n",
      "886       2   0  27.0      0      0\n",
      "887       1   1  19.0      0      0\n",
      "889       1   0  26.0      0      0\n",
      "890       3   0  32.0      0      0\n",
      "\n",
      "[714 rows x 5 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "885    0\n",
      "886    0\n",
      "887    1\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 714, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We are dropping columns that do not have an age (or that is also NaN)\n",
    "data.dropna(subset=['Age'], inplace=True)\n",
    "\n",
    "#how do we change the sex to be numbers? \n",
    "#males will be zero\n",
    "#females will be 1\n",
    "data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "#drop name, embarked, cabin, ticket, fare\n",
    "features = data.drop(['Embarked', 'Cabin', 'Ticket', 'Name', 'Fare', 'PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "labels = data['Survived']\n",
    "\n",
    "print(features)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standardizing and Scaling our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #creating instance of a scale\n",
    "scaled_features = scaler.fit_transform(features) #making our data be standardize so each feature has the same weight, the machine will find which one on their own "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Manipulate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "training_features, testing_features, training_labels, testing_labels = train_test_split(scaled_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "training_features = torch.tensor(training_features, dtype=torch.float32) \n",
    "testing_features = torch.tensor(testing_features, dtype=torch.float32)\n",
    "\n",
    "training_labels = torch.tensor(training_labels.values, dtype=torch.float32)\n",
    "testing_labels = torch.tensor(testing_labels.values, dtype=torch.float32)\n",
    "\n",
    "training_dataset = TensorDataset(training_features, training_labels)\n",
    "testing_dataset = TensorDataset(testing_features, testing_labels)\n",
    "\n",
    "training_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryModel, self).__init__() #calling binarymodel inside to utilize nn.module attributes inside our intialization\n",
    "        self.linear1 = nn.Linear(5,15) #we have 5 features, but we want 15 neurons\n",
    "        self.linear2 = nn.Linear(15, 10)\n",
    "        self.linear3 = nn.Linear(10, 5)\n",
    "        self.linear4 = nn.Linear(5, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "    \n",
    "model = BinaryModel()\n",
    "\n",
    "\n",
    "##use relu and drop to enhance model optimize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.304869681596756\n",
      "Epoch 11/200, Loss: 0.40848469734191895\n",
      "Epoch 21/200, Loss: 0.32631853222846985\n",
      "Epoch 31/200, Loss: 0.407760351896286\n",
      "Epoch 41/200, Loss: 0.5543063282966614\n",
      "Epoch 51/200, Loss: 0.44769856333732605\n",
      "Epoch 61/200, Loss: 0.3819611072540283\n",
      "Epoch 71/200, Loss: 0.20524530112743378\n",
      "Epoch 81/200, Loss: 0.44059765338897705\n",
      "Epoch 91/200, Loss: 0.42041969299316406\n",
      "Epoch 101/200, Loss: 0.36332982778549194\n",
      "Epoch 111/200, Loss: 0.4181223213672638\n",
      "Epoch 121/200, Loss: 0.3568379878997803\n",
      "Epoch 131/200, Loss: 0.40223637223243713\n",
      "Epoch 141/200, Loss: 0.4422937333583832\n",
      "Epoch 151/200, Loss: 0.3670613467693329\n",
      "Epoch 161/200, Loss: 0.47777220606803894\n",
      "Epoch 171/200, Loss: 0.40914005041122437\n",
      "Epoch 181/200, Loss: 0.36370551586151123\n",
      "Epoch 191/200, Loss: 0.45452025532722473\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "num_of_epochs = 200\n",
    "for epoch in range(num_of_epochs):\n",
    "  for features, labels in training_loader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features)\n",
    "    loss = criterion(output, labels.view(-1,1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  if epoch%10 == 0:\n",
    "    print(f'Epoch {epoch+1}/{num_of_epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748251736164093\n",
      "[Parameter containing:\n",
      "tensor([[ 6.1213e-01, -6.5545e-01,  4.6576e-01,  2.9365e-01,  1.3392e-01],\n",
      "        [ 3.4480e-01, -5.8022e-01,  2.0472e-01, -2.5705e-04,  1.5655e-01],\n",
      "        [-7.5896e-01,  9.4351e-01, -6.0306e-01, -3.5202e-01, -1.0990e-01],\n",
      "        [-6.4125e-01,  5.2991e-01, -3.5948e-01, -1.9669e-01,  1.4099e-01],\n",
      "        [ 2.5566e-03,  1.7320e-03,  2.8370e-02,  1.1704e-02,  1.9667e-02],\n",
      "        [ 3.1754e-02, -2.3145e-02,  2.8974e-02,  3.1359e-02,  1.9040e-03],\n",
      "        [-4.1112e-02,  4.4850e-02, -2.8536e-02, -2.6841e-02, -1.0189e-02],\n",
      "        [ 7.4780e-01, -9.1012e-01,  1.5922e-01, -1.0619e-03, -5.6891e-02],\n",
      "        [-3.5006e-01,  6.1307e-01, -1.7893e-01,  3.6687e-02,  3.5244e-01],\n",
      "        [-1.5763e-02,  2.0745e-02, -1.4287e-03,  1.7530e-02, -2.7208e-02],\n",
      "        [ 3.6185e-01, -5.8620e-01,  2.0445e-01,  4.3428e-01, -7.1609e-02],\n",
      "        [-2.8920e-03,  5.2711e-03, -7.1089e-03, -1.1370e-02,  7.5859e-03],\n",
      "        [ 6.1928e-01, -4.0504e-01,  5.4761e-01,  3.6232e-01, -1.4276e-02],\n",
      "        [-6.4860e-01,  8.3885e-01, -5.6939e-01,  1.5609e-01, -1.7558e-01],\n",
      "        [-5.5767e-03, -1.2456e-02, -2.1057e-02, -2.8869e-02,  1.8478e-02]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0600,  0.0320, -0.1303,  0.0227,  0.0004,  0.0014,  0.0051,  0.1715,\n",
      "         0.1624,  0.0087,  0.1151, -0.0031,  0.1208,  0.1560, -0.0103],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0376, -0.0155, -0.2074, -0.0488,  0.1852, -0.1813,  0.1294, -0.1040,\n",
      "         -0.1141, -0.1923, -0.1258,  0.2195, -0.0531,  0.2025,  0.0657],\n",
      "        [ 0.3562, -0.0070, -0.4802,  0.0807, -0.1445,  0.1481,  0.1626,  0.1548,\n",
      "          0.0091,  0.1005, -0.1796,  0.0192, -0.0190, -0.1819,  0.0536],\n",
      "        [ 0.0973,  0.1105,  0.0281,  0.0482,  0.0285, -0.0579, -0.1147, -0.0515,\n",
      "         -0.1291,  0.0413, -0.0076,  0.0086,  0.0388,  0.1324,  0.0398],\n",
      "        [ 0.1610, -0.0684,  0.1853,  0.0888,  0.2297, -0.0688, -0.0341,  0.0821,\n",
      "          0.0141,  0.0793, -0.0139, -0.0699,  0.0618, -0.0590, -0.1015],\n",
      "        [ 0.0601,  0.1905,  0.0674, -0.0466, -0.0260, -0.1494, -0.0570, -0.0531,\n",
      "         -0.1025, -0.1480,  0.0025,  0.0622,  0.0737,  0.1931, -0.0327],\n",
      "        [-0.0321,  0.0949,  0.5142,  0.3908, -0.2520,  0.1012, -0.3341, -0.4476,\n",
      "         -0.0218, -0.1620, -0.2855, -0.0417, -0.0730,  0.2514,  0.1192],\n",
      "        [ 0.0917, -0.1725,  0.2558,  0.2386,  0.0211,  0.1372,  0.1568,  0.0524,\n",
      "          0.0447,  0.1209,  0.3225, -0.0879,  0.0743, -0.1973, -0.1277],\n",
      "        [-0.1564, -0.1496,  0.0343,  0.1772, -0.0144,  0.0187,  0.2088,  0.1362,\n",
      "          0.0192,  0.0380,  0.1303, -0.0187,  0.1799, -0.0618, -0.0516],\n",
      "        [ 0.2635,  0.2134, -0.6099, -0.4163,  0.0530,  0.0184, -0.0544,  0.2945,\n",
      "         -0.3448, -0.0635,  0.3603,  0.0932,  0.0548, -0.4995, -0.1101],\n",
      "        [ 0.4249,  0.3145, -0.6251, -0.2821, -0.1379, -0.0062, -0.1913,  0.5560,\n",
      "         -0.2962, -0.0684,  0.2452, -0.1036,  0.4212, -0.3926,  0.1374]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0174, -0.0862,  0.0135, -0.0126, -0.0003, -0.0609,  0.0037, -0.0372,\n",
      "         0.2387,  0.2127], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0739,  0.3321,  0.0932, -0.0148,  0.1660,  0.2052, -0.1440,  0.1303,\n",
      "          0.1069, -0.0817],\n",
      "        [ 0.3735, -0.0802, -0.3323,  0.1369, -0.0668, -0.0697, -0.0514,  0.0185,\n",
      "          0.3976,  0.1914],\n",
      "        [ 0.0696, -0.0434,  0.0816,  0.0852,  0.0375, -0.0556,  0.1521,  0.0038,\n",
      "         -0.0628,  0.0219],\n",
      "        [ 0.1898, -0.2479, -0.1815,  0.0727, -0.0389,  0.3343, -0.0341,  0.0057,\n",
      "         -0.3325, -0.5746],\n",
      "        [-0.1296,  0.2078,  0.0549, -0.0598,  0.0745, -0.1739,  0.0230,  0.0066,\n",
      "         -0.0244, -0.1499]], requires_grad=True), Parameter containing:\n",
      "tensor([ 3.6900e-02, -2.5241e-05,  1.3271e-02, -2.4490e-01,  3.2655e-02],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0024, -0.1856, -0.0066,  0.3571,  0.0008]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2184], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy(task='binary')\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for features, labels in testing_loader:\n",
    "    output = model(features)\n",
    "    prediction = output.round()\n",
    "    accuracy.update(prediction, labels.view(-1,1))\n",
    "model.train()\n",
    "\n",
    "print(f\"Accuracy: {accuracy.compute().item()}\")\n",
    "\n",
    "\n",
    "#how to check each weight for each feature, like which one contributes the most to their survival?\n",
    "print(list(model. parameters())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".lmev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
